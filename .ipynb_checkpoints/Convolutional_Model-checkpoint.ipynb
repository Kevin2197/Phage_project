{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3daa6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "22c68f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 70, 70)\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "model = CNN()\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 70, 70)\n",
    "\n",
    "output = model.forward(input_tensor)\n",
    "print(np.array(input_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4fa1c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_images(img_folder, new_folder):\n",
    "    \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        \n",
    "        if dir1 != '.DS_Store':\n",
    "            \n",
    "            for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "                \n",
    "                new_name = os.path.splitext(file)\n",
    "                \n",
    "                \n",
    "                image_path = os.path.join(img_folder, dir1)\n",
    "                new_image_path = os.path.join(new_folder, dir1)\n",
    "\n",
    "                im1 = Image.open('{}/{}'.format(image_path, file))\n",
    "\n",
    "                rbg_im1 = im1.convert('RGB')\n",
    "\n",
    "\n",
    "                rbg_im1.save('{}/{}.jpg'.format(new_image_path, new_name[0]))\n",
    "                \n",
    "    return 0\n",
    "\n",
    "create_images('t_or_l_images', 'fixed_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d7fce0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        if dir1 != '.DS_Store':\n",
    "            for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "                \n",
    "                \n",
    "       \n",
    "                image_path= os.path.join(img_folder, dir1,  file)\n",
    "                image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "                image=cv2.resize(image, (70, 70),interpolation = cv2.INTER_AREA)\n",
    "                image=np.array(image)\n",
    "                image = image.astype('float32')\n",
    "                image /= 255 \n",
    "                img_data_array.append(image)\n",
    "                class_name.append(dir1)\n",
    "                \n",
    "    return img_data_array, class_name# extract the image array and class name\n",
    "\n",
    "dataset_X, dataset_y = create_dataset('fixed_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b88836e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_X = np.array(dataset_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8e4d4783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573, 70, 70, 3)\n",
      "(573, 3, 70, 70)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gh/3bjl5ccn37q7d9231z21l5br0000gn/T/ipykernel_77538/1347565230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "shape = dataset_X.shape\n",
    "\n",
    "print(dataset_X.shape)\n",
    "\n",
    "dataset_X = np.reshape(dataset_X, (shape[0],shape[3],shape[1],shape[2]))\n",
    "\n",
    "print(dataset_X.shape)\n",
    "\n",
    "output = model.forward(torch.tensor(dataset_X))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcabd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d707612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS IF YOU WANT TO KEEP KERNEL ALIVE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
